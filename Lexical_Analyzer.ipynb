{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    \"\"\" Class to store the tokenvalue and type of a token \"\"\"\n",
    "    def __init__(self, value=None, ttype=None, line=None, array_size=None, dec_flag=False):\n",
    "        self.tokenval = value\n",
    "        self.tokentype = ttype\n",
    "        self.line_num = line\n",
    "        self.array_size = array_size\n",
    "        self.dec_flag = dec_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getchar(m):\n",
    "    \"\"\"returns the next character from the input string m\"\"\"\n",
    "    global p\n",
    "    p+=1\n",
    "    return m[p] if p < len(m) else \"\"\n",
    "\n",
    "def isdigit(c):\n",
    "    \"\"\"returns True if input character c is a digit\"\"\"\n",
    "    Digits = [str(x) for x in range(10)]\n",
    "    return True if c in Digits else False\n",
    "\n",
    "def isalpha(c):\n",
    "    \"\"\"returns True if input character c is a letter or underscore\"\"\"\n",
    "    Uppers = [chr(x) for x in range(ord('A'),ord('Z')+1)]\n",
    "    Lowers = [chr(x) for x in range(ord('a'),ord('z')+1)]\n",
    "    return True if c in Uppers or c in Lowers or c=='_' else False\n",
    "\n",
    "def isalnum(c):\n",
    "    \"\"\"returns True if the input character c is a digit or alphabetic\"\"\"\n",
    "    return isdigit(c) or isalpha(c)\n",
    "\n",
    "def isop(c):\n",
    "    \"\"\"returns True if the input character c is a defined operator\"\"\"\n",
    "    ops = ['+', '-', '*', '/', '=', '+=', '-=', \"*=\", '/=', '++', '--', '%', '&', '|', '^', '>>', '<<', '~', '!', '?']\n",
    "    return True if c in ops else False\n",
    "\n",
    "def isrelop(c):\n",
    "    \"\"\"returns True if the input character c is a defined relational operator\"\"\"\n",
    "    ops = ['<','>', '<=', '>=', '==', '!=']\n",
    "    return True if c in ops else False\n",
    "\n",
    "def ispun(c):\n",
    "    \"\"\"returns True if the input character c is a defined punctuation\"\"\"\n",
    "    puns = ['(', ')', '{', '}', '[', ']', ';', ':', ',']\n",
    "    return True if c in puns else False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_LA():\n",
    "    \"\"\"initialize the symbol table for lexical analysis\"\"\"\n",
    "    global p                 # current input position\n",
    "    p = -1\n",
    "\n",
    "    global line_num          # current line number\n",
    "    line_num = 1\n",
    "    \n",
    "    global ST                # symbol table\n",
    "    ST = {}                  # Symbol Table for variables\n",
    "    #ST.setdefault('', 0)\n",
    "    \n",
    "    ST[\"int\"] = Token(\"int\", \"INT\")      # adding in reserved words as tokens\n",
    "    ST[\"float\"] = Token(\"float\",\"FLOAT\")\n",
    "    ST[\"if\"] = Token(\"if\",\"IF\")             \n",
    "    ST[\"else\"] = Token(\"else\",\"ELSE\")\n",
    "    ST[\"for\"] = Token(\"for\",\"FOR\")\n",
    "    ST[\"while\"] = Token(\"while\",\"WHILE\")\n",
    "    ST[\"do\"] = Token(\"do\",\"DO\")\n",
    "    ST[\"break\"] = Token(\"break\", \"BREAK\")\n",
    "    ST[\"continue\"] = Token(\"continue\", \"CONTINUE\")\n",
    "    ST[\"goto\"] = Token(\"goto\", \"GOTO\")\n",
    "    \n",
    "    global DONE              # Flag value for end of iteration\n",
    "    DONE = Token(\"$\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexan(m):\n",
    "    \"\"\"modified lexical analyzer from section 2.9, page 74\"\"\"\n",
    "    t = Token()        # create a blank token\n",
    "    global p           # string position\n",
    "    global line_num    # line number\n",
    "    global ST          # symbol table\n",
    "    global DONE        # flag for end of file\n",
    "    \n",
    "    tokenval = None    # default value for tokens\n",
    "    \n",
    "    while True:\n",
    "        lexeme = \"\"                                  # current lexeme being read\n",
    "        c = getchar(m)                               # read first character\n",
    "        \n",
    "        if c in [' ','\\t']:                          # skip over space and tab\n",
    "            pass\n",
    "        elif c == '\\n':\n",
    "            line_num += 1                            # increment line counter if newline is read\n",
    "        \n",
    "        elif isdigit(c):\n",
    "            tokenval = int(c)                        # start with integer value if char is a digit\n",
    "            c = getchar(m)                           # load next character\n",
    "            while isdigit(c):\n",
    "                tokenval = 10*tokenval + int(c)      # process next integer if char is a digit\n",
    "                c = getchar(m)                       # load next character\n",
    "            p-=1\n",
    "            t.tokenval, t.tokentype, t.line_num = tokenval,  \"NUM\", line_num\n",
    "            return t                                 # return token object \n",
    "        \n",
    "        elif isalpha(c):\n",
    "            lexeme += c                              # append character to buffer\n",
    "            c = getchar(m)                           # load next character\n",
    "            while isalnum(c):\n",
    "                lexeme += c                          # append character to buffer\n",
    "                c = getchar(m)                       # load next character\n",
    "            if lexeme not in ST.keys():\n",
    "                ST[lexeme] = Token(lexeme, \"ID\")     # add entry to symbol table (if not already present)\n",
    "            p-=1\n",
    "            t = ST[lexeme]\n",
    "            t.line_num = line_num\n",
    "            return t                                 # return the token object for the lexeme\n",
    "        \n",
    "        elif isop(c):\n",
    "            temp = c                                 # store the single character c that is an op\n",
    "            lexeme += c                              # append character to buffer\n",
    "            lexeme += getchar(m)                     # lexeme is now two characters together\n",
    "            if isop(lexeme):                         \n",
    "                t.tokenval, t.tokentype, t.line_num = lexeme, \"OP\", line_num\n",
    "                return t                             # return token object for the two character op\n",
    "            elif isrelop(lexeme):                    # check if the lexeme is a relop \n",
    "                t.tokenval, t.tokentype, t.line_num = lexeme, \"RELOP\", line_num\n",
    "                return t                             # return token object for two character relop\n",
    "            elif lexeme == '//':                     # check if the lexeme is a single line comment symbol\n",
    "                line_num += 1                        # manually increase the line number\n",
    "                while c != '\\n':                     # keep going to the next character until we get to a newline\n",
    "                    c = getchar(m)\n",
    "                    if p >= len(m): return DONE      # return done if we reach the end of the string\n",
    "                    continue\n",
    "            elif lexeme == '/*':                     # check if lexeme is a multi line comment symbol\n",
    "                c = getchar(m)\n",
    "                lexeme = c\n",
    "                lexeme += getchar(m)                 # lexeme is two characters together\n",
    "                while lexeme != '*/':                # keep going until we get to the end of comment symbol\n",
    "                    c = getchar(m)                   \n",
    "                    lexeme = lexeme[1]+c             # increment the two character lexeme along the string\n",
    "                    if c == '\\n':                    # check for new lines\n",
    "                        line_num += 1\n",
    "                continue                             \n",
    "            else:                                    # otherwise c was a single character op\n",
    "                p-=1\n",
    "                t.tokenval, t.tokentype, t.line_num = temp, \"OP\", line_num\n",
    "                return t                             # return token object for the single character op\n",
    "        \n",
    "        elif isrelop(c):\n",
    "            temp = c                                 # store the single character c that is an op\n",
    "            lexeme += c                              # append character to buffer\n",
    "            lexeme += getchar(m)                     # lexeme is now the two characters together\n",
    "            if isop(lexeme):\n",
    "                t.tokenval, t.tokentype, t.line_num = lexeme, \"OP\", line_num\n",
    "                return t                             # return object for two character op\n",
    "            elif isrelop(lexeme):                    # check if the lexeme is a relop \n",
    "                t.tokenval, t.tokentype, t.line_num = lexeme, \"RELOP\", line_num\n",
    "                return t                             # return object for two character relop\n",
    "            else:                                    # otherwise c was a single character op\n",
    "                p-=1\n",
    "                t.tokenval, t.tokentype, t.line_num = temp, \"RELOP\", line_num\n",
    "                return t                             # return object for single character relop\n",
    "        \n",
    "        elif ispun(c):\n",
    "            t.tokenval, t.tokentype, t.line_num = c, \"PUN\", line_num\n",
    "            return t                                 # return object for punctuation\n",
    "        \n",
    "        elif p >= len(m): \n",
    "            DONE.line_num = line_num\n",
    "            return DONE                # return DONE Flag for end of iteration\n",
    "        \n",
    "        else:\n",
    "            print(\"invalid character\",c,\"found on line\",line_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
